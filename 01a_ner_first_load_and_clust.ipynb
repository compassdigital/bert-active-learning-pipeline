{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1ce57dd9",
   "metadata": {},
   "source": [
    "This notebook clusters our data based on the item_for_spend and takes sample_n samples of the data for the user to tag. The output of this book is a csv in which the user has to tag all relevant entities.\n",
    "\n",
    "Expected input:\n",
    "Preprocessed csv (from 00)\n",
    "\n",
    "Expected output:\n",
    "csv for NER tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c95a5c8-95e4-4124-9504-62c03ba8fcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils as ut\n",
    "import os \n",
    "import hjson as json\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "314c7a25-3cba-4abe-9e71-555941102a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in our params file\n",
    "f = open('input_params.hjson')\n",
    "params = json.load(f)\n",
    "f.close()\n",
    "\n",
    "## Map json variable names to notebook variable names\n",
    "\n",
    "spend_col = params['core']['spend_col']\n",
    "model_name = params['core']['ner_model_name']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6fa5535e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Local nb variables\n",
    "# SQL query params\n",
    "db_type = params['core']['db_type']\n",
    "sql_code = params['core']['sql_code']\n",
    "\n",
    "# Modelling params\n",
    "sample_n = params['nb_one']['sample_n']\n",
    "\n",
    "model_type = 'named_entity_recognition' # We don't expect this parameter to change so its not being externalized\n",
    "\n",
    "# Algorithm specific params\n",
    "max_size = 1000\n",
    "use_pretrained_model = params['core']['use_pretrained_model']\n",
    "model_architecture = params['core']['model_architecture']\n",
    "model_path = params['core']['model_path']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13f7dab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_df_for_sampling(df, max_size, spend_col):\n",
    "# Limit our NER to a max size so we don't overflow \n",
    "\n",
    "    if df.shape[0] > max_size:\n",
    "        print('Input df too large. Pruning...')\n",
    "        pct = max_size/df.shape[0]\n",
    "        df = df[df[spend_col] > df[spend_col].quantile(.1)] # Focus on the top 90% of data b/c it tends to be cleaner\n",
    "        df = df.sample(n=max_size, random_state=7)\n",
    "        print(f'Percent of data kept: {pct}')\n",
    "    return df\n",
    "\n",
    "def k_means_sampling(df, sample_n, use_pretrained_model, model_path, model_architecture, item_col='item_for_selection'):\n",
    "    # Use k means to sample our dataset\n",
    "\n",
    "    CRS = ut.ClustResample(\n",
    "        df = df,\n",
    "        input_col = item_col,\n",
    "        sample_n = sample_n,\n",
    "        use_pretrained_model = use_pretrained_model,\n",
    "        model_path = model_path,\n",
    "        model_architecture = model_architecture\n",
    "    )\n",
    "\n",
    "    CRS.bert_vecs()\n",
    "    CRS.kmeans()\n",
    "    CRS.sample_centroids()\n",
    "    CRS.format_for_ner_labelling()\n",
    "    return CRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4194d08a-3ddc-40a0-ab25-c192937be063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input df too large. Pruning...\n",
      "Percent of data kept: 0.0021695974311966414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at epoch_95 were not used when initializing TFBertModel: ['mlm___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFBertModel were not initialized from the model checkpoint at epoch_95 and are newly initialized: ['bert/pooler/dense/kernel:0', 'bert/pooler/dense/bias:0']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "1000it [00:00, 5717.96it/s]\n",
      "/home/shared/shared_sandbox/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1318: FutureWarning: algorithm='full' is deprecated, it will be removed in 1.3. Using 'lloyd' instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Run the functions in the notebook\n",
    "df = pd.read_csv(f'{model_type}/{model_name}/data/{model_name}_preprocessed.csv')\n",
    "df = trim_df_for_sampling(df, max_size, spend_col)\n",
    "CRS = k_means_sampling(df, sample_n, use_pretrained_model, model_path, model_architecture)\n",
    "CRS.out.to_csv(f'{model_type}/{model_name}/data/{model_name}_label_set_round1_n{sample_n}.csv',index = False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e2d1cdde",
   "metadata": {},
   "source": [
    "### Validation tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a91f1fbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_for_selection</th>\n",
       "      <th>position</th>\n",
       "      <th>word</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>(v) honey - sesame tofu (av,s)(s</td>\n",
       "      <td>0</td>\n",
       "      <td>(v)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>(v) honey - sesame tofu (av,s)(s</td>\n",
       "      <td>1</td>\n",
       "      <td>honey</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>(v) honey - sesame tofu (av,s)(s</td>\n",
       "      <td>2</td>\n",
       "      <td>-</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>(v) honey - sesame tofu (av,s)(s</td>\n",
       "      <td>3</td>\n",
       "      <td>sesame</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>(v) honey - sesame tofu (av,s)(s</td>\n",
       "      <td>4</td>\n",
       "      <td>tofu</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>wrap chicken caesar</td>\n",
       "      <td>1</td>\n",
       "      <td>chicken</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>wrap chicken caesar</td>\n",
       "      <td>2</td>\n",
       "      <td>caesar</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>wt ham sandwich</td>\n",
       "      <td>0</td>\n",
       "      <td>wt</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>wt ham sandwich</td>\n",
       "      <td>1</td>\n",
       "      <td>ham</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>wt ham sandwich</td>\n",
       "      <td>2</td>\n",
       "      <td>sandwich</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>318 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   item_for_selection  position      word tag\n",
       "295  (v) honey - sesame tofu (av,s)(s         0       (v)    \n",
       "296  (v) honey - sesame tofu (av,s)(s         1     honey    \n",
       "297  (v) honey - sesame tofu (av,s)(s         2         -    \n",
       "298  (v) honey - sesame tofu (av,s)(s         3    sesame    \n",
       "299  (v) honey - sesame tofu (av,s)(s         4      tofu    \n",
       "..                                ...       ...       ...  ..\n",
       "105               wrap chicken caesar         1   chicken    \n",
       "106               wrap chicken caesar         2    caesar    \n",
       "249                   wt ham sandwich         0        wt    \n",
       "250                   wt ham sandwich         1       ham    \n",
       "251                   wt ham sandwich         2  sandwich    \n",
       "\n",
       "[318 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview the df\n",
    "df = CRS.out\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "508a0ea8-e734-46f7-b9b7-b67eaa081f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure our output df has the right columns\n",
    "# If this fails, make sure that the columns tested for actually reside in your dataset\n",
    "\n",
    "cols = list(df)\n",
    "assert(all(item in cols for item in ['item_for_selection', 'position', 'word', 'tag']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ab73bed-8724-4f0e-999b-b4b426af232e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure our output df has at least one row\n",
    "# If this fails, make sure your data wasn't accidentally dropped\n",
    "\n",
    "assert(df.shape[0]>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fbce48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shared-sandbox",
   "language": "python",
   "name": "shared-sandbox"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "724620819c1b67a8719511b894080dad117c54c2ce08619897482b96056206e2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
